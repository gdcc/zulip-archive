<html>
<head><meta charset="utf-8"><title>Data upload questions Â· community Â· Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://gdcc.github.io/zulip-archive/stream/375707-community/index.html">community</a></h2>
<h3>Topic: <a href="https://gdcc.github.io/zulip-archive/stream/375707-community/topic/Data.20upload.20questions.html">Data upload questions</a></h3>

<hr>

<base href="https://dataverse.zulipchat.com">

<head><link href="https://gdcc.github.io/zulip-archive/style.css" rel="stylesheet"></head>

<a name="455869505"></a>
<h4><a href="https://dataverse.zulipchat.com#narrow/stream/375707-community/topic/Data%20upload%20questions/near/455869505" class="zl"><img src="https://gdcc.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Simon Carroll <a href="https://gdcc.github.io/zulip-archive/stream/375707-community/topic/Data.20upload.20questions.html#455869505">(Aug 02 2024 at 08:21)</a>:</h4>
<p>Good morning! I have deployed a test instance of Dataverse for the Barcelona Super Computer center. Some users are asking about the best way to upload data. For large files is there a recommended API?  (Users are asking if PUT can be used instead of post in order to allow chunking of the transfer. I havent found much about it in the documentation).  Am I missing another way of chunking large files ? Also for parrelel transfers are there any recomendations ?</p>



<a name="455915345"></a>
<h4><a href="https://dataverse.zulipchat.com#narrow/stream/375707-community/topic/Data%20upload%20questions/near/455915345" class="zl"><img src="https://gdcc.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Philip Durbin ðŸš€ <a href="https://gdcc.github.io/zulip-archive/stream/375707-community/topic/Data.20upload.20questions.html#455915345">(Aug 02 2024 at 11:47)</a>:</h4>
<p>Hi! Are you using S3-compatible storage? Do you have "direct upload" enabled? If so, I'd recommend trying DVUploader: <a href="https://guides.dataverse.org/en/6.3/user/dataset-management.html#command-line-dvuploader">https://guides.dataverse.org/en/6.3/user/dataset-management.html#command-line-dvuploader</a></p>



<a name="455926231"></a>
<h4><a href="https://dataverse.zulipchat.com#narrow/stream/375707-community/topic/Data%20upload%20questions/near/455926231" class="zl"><img src="https://gdcc.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Simon Carroll <a href="https://gdcc.github.io/zulip-archive/stream/375707-community/topic/Data.20upload.20questions.html#455926231">(Aug 02 2024 at 12:48)</a>:</h4>
<p><span class="user-mention silent" data-user-id="598112">Philip Durbin</span> <a href="#narrow/stream/375707-community/topic/Data.20upload.20questions/near/455915345">said</a>:</p>
<blockquote>
<p>Hi! Are you using S3-compatible storage? Do you have "direct upload" enabled? If so, I'd recommend trying DVUploader: <a href="https://guides.dataverse.org/en/6.3/user/dataset-management.html#command-line-dvuploader">https://guides.dataverse.org/en/6.3/user/dataset-management.html#command-line-dvuploader</a></p>
</blockquote>
<p>Hello! Thanks for the reply. At the moment no. We will potentially be using swift in the future. For the moment it is just an openstack storage volume mounted on the VM. Later it could be some combination of swift with our ibm spectrum archive storage system.</p>



<a name="455926343"></a>
<h4><a href="https://dataverse.zulipchat.com#narrow/stream/375707-community/topic/Data%20upload%20questions/near/455926343" class="zl"><img src="https://gdcc.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Simon Carroll <a href="https://gdcc.github.io/zulip-archive/stream/375707-community/topic/Data.20upload.20questions.html#455926343">(Aug 02 2024 at 12:48)</a>:</h4>
<p>Do you have anny recommendations for best way to upload files in the current architecture ?</p>



<a name="455928871"></a>
<h4><a href="https://dataverse.zulipchat.com#narrow/stream/375707-community/topic/Data%20upload%20questions/near/455928871" class="zl"><img src="https://gdcc.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Philip Durbin ðŸš€ <a href="https://gdcc.github.io/zulip-archive/stream/375707-community/topic/Data.20upload.20questions.html#455928871">(Aug 02 2024 at 13:02)</a>:</h4>
<p>Ok, so no S3. No Globus either, I assume: <a href="https://guides.dataverse.org/en/6.3/admin/integrations.html#globus">https://guides.dataverse.org/en/6.3/admin/integrations.html#globus</a></p>



<a name="455929001"></a>
<h4><a href="https://dataverse.zulipchat.com#narrow/stream/375707-community/topic/Data%20upload%20questions/near/455929001" class="zl"><img src="https://gdcc.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Philip Durbin ðŸš€ <a href="https://gdcc.github.io/zulip-archive/stream/375707-community/topic/Data.20upload.20questions.html#455929001">(Aug 02 2024 at 13:03)</a>:</h4>
<p>For a one off large file upload to non-S3, I've been chatting with <span class="user-mention" data-user-id="735407">@MarÃ­a A. Matienzo</span> about a way to do it over at <a class="stream-topic" data-stream-id="378866" href="/#narrow/stream/378866-troubleshooting/topic/large.20uploads.20via.20native.20api.20workaround">#troubleshooting &gt; large uploads via native api workaround</a></p>



<a name="455930261"></a>
<h4><a href="https://dataverse.zulipchat.com#narrow/stream/375707-community/topic/Data%20upload%20questions/near/455930261" class="zl"><img src="https://gdcc.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Philip Durbin ðŸš€ <a href="https://gdcc.github.io/zulip-archive/stream/375707-community/topic/Data.20upload.20questions.html#455930261">(Aug 02 2024 at 13:11)</a>:</h4>
<p>As <span class="user-mention" data-user-id="626369">@Don Sizemore</span> reminded me, there's also the concept of Trusted Remote Storage: <a href="https://guides.dataverse.org/en/6.3/installation/config.html#trusted-remote-storage">https://guides.dataverse.org/en/6.3/installation/config.html#trusted-remote-storage</a></p>
<p>In short, Dataverse doesn't manage the files. You just tell Dataverse where the files live.</p>



<hr><p>Last updated: Nov 01 2025 at 23:12 UTC</p>
</html>