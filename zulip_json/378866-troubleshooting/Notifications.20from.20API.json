[
    {
        "content": "<p>Is there a way to get a notification that a dataset has been created when creating a dataset via API? If I create a dataset via the UI, I get an e-mail notification. I would like the API to notify me too. - Actually I would like the API (create dataset) to notify all admins of the collection the dataset is added to.</p>",
        "id": 399594991,
        "sender_full_name": "Sherry Lake",
        "timestamp": 1698783139
    },
    {
        "content": "<p>It's a known issue, I'm afraid: notification/email inconsistencies when creating a dataset via API <a href=\"https://github.com/IQSS/dataverse/issues/4043\">#4043</a></p>",
        "id": 399597440,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1698784281
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"598432\">@Slava Tykhonov</span> would probably suggest adding a database trigger: <a href=\"https://github.com/IQSS/dataverse-docker/tree/master/triggers\">https://github.com/IQSS/dataverse-docker/tree/master/triggers</a></p>",
        "id": 399597474,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1698784299
    },
    {
        "content": "<p>via the modularity doc: <a href=\"https://docs.google.com/document/d/1bXzV-cBBYTs5j8bzhdNpKBVfo29qulxue3WAn3Uzvos/edit?usp=sharing\">https://docs.google.com/document/d/1bXzV-cBBYTs5j8bzhdNpKBVfo29qulxue3WAn3Uzvos/edit?usp=sharing</a></p>",
        "id": 399597835,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1698784438
    },
    {
        "content": "<p>Hooking on to this topic; configurable webhooks upon Dataverse actions or an event stack endpoint on the API would be absolutely amazing.</p>",
        "id": 399672135,
        "sender_full_name": "Thomas van Erven",
        "timestamp": 1698823354
    },
    {
        "content": "<p>Use case here is that we plan to move to object storage, but unfortunately, the vendor that we intend to use has a file size limit that's quite low. There's a number of approaches I've offered, but the option I plan to push for is to perform the move sneakily (automagically isolate files smaller than the limit at predetermined interval (say, cron), copy them to object storage, update DV's database to point it directly). If I had an event stream of a webhook, however, I could handle this much more gracefully by listening specifically to events that would generate when people did stuff in the Dataverse.</p>",
        "id": 399672761,
        "sender_full_name": "Thomas van Erven",
        "timestamp": 1698823644
    },
    {
        "content": "<p>(No rush, I can move forward without such a system, and I imagine you have other things lined up first, but it would open up DV to become a central brain in distributed applications, which would be awesome.)</p>",
        "id": 399673516,
        "sender_full_name": "Thomas van Erven",
        "timestamp": 1698824006
    },
    {
        "content": "<p>I don't know where I wrote something about this before, but I definitely talked with people about it at DCM23. My vision here would be a pluggable notification system where mails are just one option, but you can provide others, like Webhooks, Kafka, Rabbit,...</p>",
        "id": 399677876,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1698826222
    },
    {
        "content": "<p>Hmm, great ideas. Please go ahead and create issues for these!</p>",
        "id": 399713332,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1698840839
    }
]