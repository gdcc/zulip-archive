[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"598183\">@Oliver Bertuch</span> had the idea of providing a custom filesystem to remotely access and upload files via PyDataverse.  This works already and will soon be put into a PR. </p>\n<p>Another idea was to allow crawling ZIP files, similar to the Zip Previewer. Unfortunately the previewer initially downloads the Zip file and then displays the content. Hence my question, is there a way or could you think of providing this as a Dataverse endpoint? At least listing the content would be beneficial.</p>",
        "id": 432852800,
        "sender_full_name": "Jan Range",
        "timestamp": 1712909054
    },
    {
        "content": "<p>I may not be following very well..</p>\n<p>I did see this issue about a PyFilesystem implementation: <a href=\"https://github.com/gdcc/pyDataverse/issues/178\">https://github.com/gdcc/pyDataverse/issues/178</a></p>\n<p>But now you're asking about zip files? You want to preview the contents from pyDataverse?</p>",
        "id": 432885844,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1712922141
    },
    {
        "content": "<p>Exactly! The idea goes like this: someone wants to use a single file from a ZIP living on Dataverse. Using the ZIP Pyfilesystem backed by the Dataverse Pyfilesystem, you would be able to retrieve it, without downloading all of it.</p>",
        "id": 432886046,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712922230
    },
    {
        "content": "<p>Does the existing HTTP Range header support help here? Or do we need a new API endpoint? You just want the list of contents in the zip file, right?</p>",
        "id": 432886245,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1712922307
    },
    {
        "content": "<p>I'm not sure how the ZIP file previewer does it</p>",
        "id": 432886346,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712922358
    },
    {
        "content": "<p>It uses HTTPRange too</p>",
        "id": 432886405,
        "sender_full_name": "Jan Range",
        "timestamp": 1712922366
    },
    {
        "content": "<p>It must extract the list of files from the ZIP to display it</p>",
        "id": 432886436,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712922380
    },
    {
        "content": "<p>And then probably has coded in the ranges to be able to download a single file from the ZIP without downloading the whole ZIP file first</p>",
        "id": 432886515,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712922416
    },
    {
        "content": "<p>I have never used HTTP Range though. Would need to dig a bit into this.</p>",
        "id": 432886547,
        "sender_full_name": "Jan Range",
        "timestamp": 1712922432
    },
    {
        "content": "<p>Range has your name on it! Please see <a href=\"https://guides.dataverse.org/en/6.2/api/dataaccess.html#headers\">https://guides.dataverse.org/en/6.2/api/dataaccess.html#headers</a></p>",
        "id": 432886758,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1712922513
    },
    {
        "content": "<p>Hehe should be familiar thing to me <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 432886832,
        "sender_full_name": "Jan Range",
        "timestamp": 1712922546
    },
    {
        "content": "<p>In my imagination the zip previewer/downloader uses the Range header to get the listing of files. Then it presents the list to the user. When the user clicks a file to download, it usese the Range header again to download just the bytes for that file.</p>",
        "id": 432886913,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1712922587
    },
    {
        "content": "<p>I don't think it downloads the entire zip file to get the listing of files. I sure hope not.</p>",
        "id": 432887016,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1712922618
    },
    {
        "content": "<p>Maybe there is something to deal with this already present in PyFilesystems. Will check!</p>",
        "id": 432887024,
        "sender_full_name": "Jan Range",
        "timestamp": 1712922622
    },
    {
        "content": "<p>Probably <a href=\"https://docs.pyfilesystem.org/en/latest/_modules/fs/zipfs.html#ZipFS\">https://docs.pyfilesystem.org/en/latest/_modules/fs/zipfs.html#ZipFS</a> does not support remote ZIP files or range requests...</p>",
        "id": 432887936,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712922972
    },
    {
        "content": "<p>I have found another library that supports opening remote S3 and I guess HTTP too:</p>\n<p><a href=\"https://pypi.org/project/smart-open/\">https://pypi.org/project/smart-open/</a></p>",
        "id": 432888038,
        "sender_full_name": "Jan Range",
        "timestamp": 1712923018
    },
    {
        "content": "<p>Giving it a try now</p>",
        "id": 432888057,
        "sender_full_name": "Jan Range",
        "timestamp": 1712923029
    },
    {
        "content": "<p>Oh wow!</p>",
        "id": 432888254,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712923107
    },
    {
        "content": "<p>Looks amazing!</p>",
        "id": 432888267,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712923110
    },
    {
        "content": "<p>The unicorn we needed <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 432888286,
        "sender_full_name": "Jan Range",
        "timestamp": 1712923124
    },
    {
        "content": "<p>Hmm does it support ZIP?</p>",
        "id": 432888461,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712923200
    },
    {
        "content": "<p>Loads ZIPs very well from remote! At least we are getting some binary. Checking the content now</p>",
        "id": 432888606,
        "sender_full_name": "Jan Range",
        "timestamp": 1712923230
    },
    {
        "content": "<p><a href=\"/user_uploads/53090/a7K5-lEzXwN7Vn-TpJ3ZvD1q/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/53090/a7K5-lEzXwN7Vn-TpJ3ZvD1q/image.png\" title=\"image.png\"><img src=\"/user_uploads/53090/a7K5-lEzXwN7Vn-TpJ3ZvD1q/image.png\"></a></div>",
        "id": 432888628,
        "sender_full_name": "Jan Range",
        "timestamp": 1712923239
    },
    {
        "content": "<p>Might need to add a compression handler...</p>",
        "id": 432888683,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712923263
    },
    {
        "content": "<p>Remote file was a <code>tar</code> file btw.</p>",
        "id": 432888730,
        "sender_full_name": "Jan Range",
        "timestamp": 1712923278
    },
    {
        "content": "<p>From looking at the library, Im not sure it supports extracting the list of files and extracting parts of the ZIP file via HTTP range requests</p>",
        "id": 432889081,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712923373
    },
    {
        "content": "<p>Yes, that seems impossible. I can't find any documentation about this, and there is no dedicated method. Would it be a contender for the S3 download though? Seems pretty simple to me</p>",
        "id": 432889307,
        "sender_full_name": "Jan Range",
        "timestamp": 1712923449
    },
    {
        "content": "<p>Related and Interesting: <a href=\"https://github.com/piskvorky/smart_open/issues/725\">https://github.com/piskvorky/smart_open/issues/725</a></p>",
        "id": 432889677,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712923588
    },
    {
        "content": "<p>I suppose the ZIP file previewer is loading a few kilobytes from the end of the zip file (the size is known from metadata IIRC or maybe ranges support negative values)</p>",
        "id": 432890699,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712924010
    },
    {
        "content": "<p>If you find the central directory header signature you know you got it all (0x02014b50) and can start browsing for the files</p>",
        "id": 432890869,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712924081
    },
    {
        "content": "<p><a href=\"https://en.wikipedia.org/wiki/ZIP_(file_format)\">https://en.wikipedia.org/wiki/ZIP_(file_format)</a></p>",
        "id": 432890887,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712924086
    },
    {
        "content": "<p>Oh wait it actually is even easier when you know the last byte... There is a record about the central directory at the end of it all</p>",
        "id": 432891038,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712924155
    },
    {
        "content": "<p>Again, it should be possible to see what the ZIP file previewer is doing and try to transfer that to Python</p>",
        "id": 432891235,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712924229
    },
    {
        "content": "<p>Cool! Learned something new today <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> Going to check it out!</p>",
        "id": 432891321,
        "sender_full_name": "Jan Range",
        "timestamp": 1712924274
    },
    {
        "content": "<p>Feels so good to do some coding again after a week full of enzyme catalysis stuff <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 432891517,
        "sender_full_name": "Jan Range",
        "timestamp": 1712924345
    },
    {
        "content": "<p>Some StackOverflow digging has helped!</p>\n<p><a href=\"https://stackoverflow.com/a/17434121\">https://stackoverflow.com/a/17434121</a> (especially the last section with <code>ZipFile</code>)</p>",
        "id": 432898102,
        "sender_full_name": "Jan Range",
        "timestamp": 1712926567
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"652521\">@Markus HaarlÃ¤nder</span> created the zip previewer/downloader. Maybe he can help.</p>",
        "id": 432900437,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1712927271
    },
    {
        "content": "<p>I think I have it!</p>\n<p><a href=\"/user_uploads/53090/KD0FOQrevKRbcNDuCCQX2uva/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/53090/KD0FOQrevKRbcNDuCCQX2uva/image.png\" title=\"image.png\"><img src=\"/user_uploads/53090/KD0FOQrevKRbcNDuCCQX2uva/image.png\"></a></div>",
        "id": 432901365,
        "sender_full_name": "Jan Range",
        "timestamp": 1712927575
    },
    {
        "content": "<p>Original file - <a href=\"https://darus.uni-stuttgart.de/file.xhtml?persistentId=doi:10.18419/darus-3372/7\">https://darus.uni-stuttgart.de/file.xhtml?persistentId=doi:10.18419/darus-3372/7</a></p>",
        "id": 432901472,
        "sender_full_name": "Jan Range",
        "timestamp": 1712927613
    },
    {
        "content": "<p>That looks promising!</p>",
        "id": 432901806,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712927752
    },
    {
        "content": "<p>It might be necessary to repeat the reading of 256k if the ZIP file is large</p>",
        "id": 432901898,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712927772
    },
    {
        "content": "<p>Yes, I will add an iterative process. According to StackOverflow ZipFile will raise an error if it is not enough. Hence, I would just repeat and increment until there is no error.</p>",
        "id": 432902056,
        "sender_full_name": "Jan Range",
        "timestamp": 1712927837
    },
    {
        "content": "<p>Sounds good to me!</p>",
        "id": 432902136,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712927879
    },
    {
        "content": "<p>So this would be a feature of DataverseFS, right?</p>",
        "id": 432902215,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712927897
    },
    {
        "content": "<p>Yes, would be a great feature to have! Next challenge though is to extract a specific file</p>",
        "id": 432902287,
        "sender_full_name": "Jan Range",
        "timestamp": 1712927925
    },
    {
        "content": "<p>Oh and what about retrieval of a file from the ZIP? You didn't take a look at that yet, right?</p>",
        "id": 432902337,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712927944
    },
    {
        "content": "<p>I would suggest to first nail this down on the example and then generalize it in DataverseFS</p>",
        "id": 432902363,
        "sender_full_name": "Jan Range",
        "timestamp": 1712927959
    },
    {
        "content": "<p>Ha! You beat me to it <span aria-label=\"racecar\" class=\"emoji emoji-1f3ce\" role=\"img\" title=\"racecar\">:racecar:</span></p>",
        "id": 432902368,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712927961
    },
    {
        "content": "<p>Haha</p>",
        "id": 432902375,
        "sender_full_name": "Jan Range",
        "timestamp": 1712927965
    },
    {
        "content": "<p>Will look into this. Guess the ZIP Preview has some ideas already</p>",
        "id": 432902530,
        "sender_full_name": "Jan Range",
        "timestamp": 1712928011
    },
    {
        "content": "<p>Probably they extract the byte locations from the ZIP directory and merge it all into a request including the range</p>",
        "id": 432902714,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1712928073
    },
    {
        "content": "<p>That makes sense</p>",
        "id": 432903056,
        "sender_full_name": "Jan Range",
        "timestamp": 1712928188
    },
    {
        "content": "<p>Maybe ZipFile has some nice utilities for that</p>",
        "id": 432903070,
        "sender_full_name": "Jan Range",
        "timestamp": 1712928198
    },
    {
        "content": "<p>Hi guys. <br>\nSeems you already mastered most of it. Yes, the ZipPreviewer utilizes HTTP Range Requests to read the central directory of a ZIP file first, and to download and extract single files from the ZIP (using ranges from the central directory). It makes use of a great JavaScript Library which can do all of these things: <a href=\"https://github.com/gildas-lormeau/zip.js\">https://github.com/gildas-lormeau/zip.js</a>. But I don't know about a Python library</p>",
        "id": 432904400,
        "sender_full_name": "Markus HaarlÃ¤nder",
        "timestamp": 1712928639
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"652521\">@Markus HaarlÃ¤nder</span> thanks for the info! Glad to hear we are on the right track <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 432932679,
        "sender_full_name": "Jan Range",
        "timestamp": 1712936953
    },
    {
        "content": "<p>Coincidentally, right after reading your message I stumbled across something similar to <code>zip.js</code> and it does exactly what we want! The library is called <a href=\"https://github.com/gtsystem/python-remotezip\">remotezip</a></p>\n<p><a href=\"/user_uploads/53090/HDaSz1IyRUxTJgrXXHdgawzd/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/53090/HDaSz1IyRUxTJgrXXHdgawzd/image.png\" title=\"image.png\"><img src=\"/user_uploads/53090/HDaSz1IyRUxTJgrXXHdgawzd/image.png\"></a></div>",
        "id": 432933056,
        "sender_full_name": "Jan Range",
        "timestamp": 1712937058
    },
    {
        "content": "<p>mmm, pythonic <span aria-label=\"yum\" class=\"emoji emoji-1f60b\" role=\"img\" title=\"yum\">:yum:</span></p>",
        "id": 432933220,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1712937103
    },
    {
        "content": "<p>For reference, this is a 2.8 GB file, and even this works pretty well/fast. Super nice!!</p>\n<p><a href=\"/user_uploads/53090/-cmGQ9PYFRLLX6BzncsYnRhm/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/53090/-cmGQ9PYFRLLX6BzncsYnRhm/image.png\" title=\"image.png\"><img src=\"/user_uploads/53090/-cmGQ9PYFRLLX6BzncsYnRhm/image.png\"></a></div>",
        "id": 432933950,
        "sender_full_name": "Jan Range",
        "timestamp": 1712937304
    },
    {
        "content": "<p>We're going to have a lot to talk about at the next pyDataverse meeting. <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 432934347,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1712937422
    },
    {
        "content": "<p>True <span aria-label=\"grinning face with smiling eyes\" class=\"emoji emoji-1f601\" role=\"img\" title=\"grinning face with smiling eyes\">:grinning_face_with_smiling_eyes:</span></p>",
        "id": 432934471,
        "sender_full_name": "Jan Range",
        "timestamp": 1712937456
    },
    {
        "content": "<p>The code for listing the contents of a ZIP file and downloading specific parts is working well. I have separated the Dataverse and Zip Filesystem, so passing a <code>DataFile</code> object to the ZIP filesystem is necessary. Here is a working example:</p>\n<p><a href=\"/user_uploads/53090/pdBCvnUvWoVfZ2Hg2BHBdFHK/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/53090/pdBCvnUvWoVfZ2Hg2BHBdFHK/image.png\" title=\"image.png\"><img src=\"/user_uploads/53090/pdBCvnUvWoVfZ2Hg2BHBdFHK/image.png\"></a></div>",
        "id": 433243732,
        "sender_full_name": "Jan Range",
        "timestamp": 1713173866
    },
    {
        "content": "<p>On the left sidebar, you can see the downloaded part of the ZIP file. Once I have implemented the <code>write</code> method to upload data files, I will create a pull request <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 433243973,
        "sender_full_name": "Jan Range",
        "timestamp": 1713173918
    },
    {
        "content": "<p>This looks amazing!</p>",
        "id": 433245718,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713174424
    },
    {
        "content": "<p>Question: should the name of the ZipFS rather be \"RemoteZipFS\" to make it more obvious what this is about? Someone might want to combine it with the ZipFS shipped with PyFilesystem</p>",
        "id": 433245904,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713174482
    },
    {
        "content": "<p>Yes, that makes sense! Will rename it <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 433246004,
        "sender_full_name": "Jan Range",
        "timestamp": 1713174515
    },
    {
        "content": "<p>Upload works too <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> </p>\n<p><a href=\"/user_uploads/53090/OgPgE8Qfoa_iLGqIrvPJXN-F/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/53090/OgPgE8Qfoa_iLGqIrvPJXN-F/image.png\" title=\"image.png\"><img src=\"/user_uploads/53090/OgPgE8Qfoa_iLGqIrvPJXN-F/image.png\"></a></div>",
        "id": 433267003,
        "sender_full_name": "Jan Range",
        "timestamp": 1713181170
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"598112\">@Philip Durbin</span> Would Stefano be interested in putting the \"Compute on Data\" logic into the filesystem? I think this would be the right place</p>",
        "id": 433268121,
        "sender_full_name": "Jan Range",
        "timestamp": 1713181497
    },
    {
        "content": "<p>Maybe! Let's see what <span class=\"user-mention\" data-user-id=\"637063\">@Leo Andreev</span> thinks.</p>",
        "id": 433524948,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1713274762
    },
    {
        "content": "<p>I think the filesystem is pretty close to the finish. It is now possible to write files similar to regular filesystems using the <code>open(\"my.file\", \"w\")</code> way. Will create a new data file upon closing and also supports S3 due to DVUploader. Here is an example:</p>\n<p><a href=\"/user_uploads/53090/AsoYd0YE1F1aEx8UQfTd2e88/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/53090/AsoYd0YE1F1aEx8UQfTd2e88/image.png\" title=\"image.png\"><img src=\"/user_uploads/53090/AsoYd0YE1F1aEx8UQfTd2e88/image.png\"></a></div>",
        "id": 433669823,
        "sender_full_name": "Jan Range",
        "timestamp": 1713334436
    },
    {
        "content": "<p>Feels almost like you are writing files to the hard drive <span aria-label=\"stuck out tongue\" class=\"emoji emoji-1f61b\" role=\"img\" title=\"stuck out tongue\">:stuck_out_tongue:</span></p>",
        "id": 433670183,
        "sender_full_name": "Jan Range",
        "timestamp": 1713334488
    },
    {
        "content": "<p>Would it be an option to have a \"with\" thing? So on any close the file automatically gets uploaded?</p>",
        "id": 433677844,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336082
    },
    {
        "content": "<p>Do you mean for the filesystem itself?</p>",
        "id": 433677881,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336111
    },
    {
        "content": "<p>Or is this already happening?</p>",
        "id": 433677947,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336128
    },
    {
        "content": "<p>The with operation is already available for files itself</p>",
        "id": 433677950,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336130
    },
    {
        "content": "<p>You can either use the with to close automatically or invoke it by yourself afterwards for the upload</p>",
        "id": 433677989,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336154
    },
    {
        "content": "<p>Ah! So the second loop already does the upload in the background</p>",
        "id": 433677998,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336155
    },
    {
        "content": "<p><a href=\"/user_uploads/53090/IOCJ5z6Xa5Jb3XjaZBbaWDHQ/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/53090/IOCJ5z6Xa5Jb3XjaZBbaWDHQ/image.png\" title=\"image.png\"><img src=\"/user_uploads/53090/IOCJ5z6Xa5Jb3XjaZBbaWDHQ/image.png\"></a></div>",
        "id": 433678034,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336173
    },
    {
        "content": "<p>And the third loop is just an example to upload other files on disk?</p>",
        "id": 433678046,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336178
    },
    {
        "content": "<p>Yes, exactly <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 433678054,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336185
    },
    {
        "content": "<p>Great!</p>",
        "id": 433678067,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336191
    },
    {
        "content": "<p>This is really great!</p>",
        "id": 433678080,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336197
    },
    {
        "content": "<p>I thought it would make sense to have a local file option too, since the usual <code>open</code> operation is blocking and yet cant be parallelized</p>",
        "id": 433678126,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336219
    },
    {
        "content": "<p>Does it support remote files (for download), too?</p>",
        "id": 433678138,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336232
    },
    {
        "content": "<p>Yes, you can download any file from a dataset including zip members</p>",
        "id": 433678203,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336252
    },
    {
        "content": "<p>No I meant files that are in a remote store.</p>",
        "id": 433678239,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336271
    },
    {
        "content": "<p>So not in S3 and not stored in Dataverse</p>",
        "id": 433678258,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336286
    },
    {
        "content": "<p>But referenced using a URL</p>",
        "id": 433678273,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336295
    },
    {
        "content": "<p>Ah alright, I have not tested this yet, but I am sure there are ways to integrate it</p>",
        "id": 433678300,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336313
    },
    {
        "content": "<p>It would be great to enable registering URL handlers here</p>",
        "id": 433678331,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336334
    },
    {
        "content": "<p>You mean in a way to transfer from a remote store to dataverse?</p>",
        "id": 433678401,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336366
    },
    {
        "content": "<p>Would be great if there is a way to not have to download the intermediate file then</p>",
        "id": 433678446,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336389
    },
    {
        "content": "<p>So people could store something using git-annex and receive the file when they execute the python script</p>",
        "id": 433678451,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336391
    },
    {
        "content": "<p>Do you have an example for this? Havent used git-annex yet</p>",
        "id": 433678502,
        "sender_full_name": "Jan Range",
        "timestamp": 1713336425
    },
    {
        "content": "<p>That way they could very naturally interact with the files and they would be fetched as necessary</p>",
        "id": 433678506,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336426
    },
    {
        "content": "<p>Ha storing the git annex thing was a wild idea at distribits</p>",
        "id": 433678526,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336445
    },
    {
        "content": "<p>For now there might be examples using HTTP and Globus links</p>",
        "id": 433678547,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336470
    },
    {
        "content": "<p>Let me get to work then I'll try to cook some better example. Typing this on my mobile is hard...</p>",
        "id": 433678672,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713336522
    },
    {
        "content": "<p>Alright. From <a href=\"https://guides.dataverse.org/en/latest/api/native-api.html#add-remote-file-api\">https://guides.dataverse.org/en/latest/api/native-api.html#add-remote-file-api</a> we know that files registered as remote files contain lots of information about the file. The most important bit is probably the storage identifier.</p>",
        "id": 433688545,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338101
    },
    {
        "content": "<p>It will contain a URL that has been configured as a valid base url in the store plus a path within that location</p>",
        "id": 433689084,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338168
    },
    {
        "content": "<p>The filesystem will be presented with this information when downloading the file metadata</p>",
        "id": 433689190,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338216
    },
    {
        "content": "<p>So it would know about the files and folder structures</p>",
        "id": 433689229,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338235
    },
    {
        "content": "<p>But it could not download the file from the Dataverse instance</p>",
        "id": 433689263,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338249
    },
    {
        "content": "<p>Which means that the filesystem would need to understand how to resolve the URLs into a file</p>",
        "id": 433689878,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338501
    },
    {
        "content": "<p>The example JSON to register the remote file has the example storage ID <code>trsa://themes/custom/qdr/images/CoreTrustSeal-logo-transparent.png</code></p>",
        "id": 433690048,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338568
    },
    {
        "content": "<p>Users of the filesystem would need some means to register a handler that knows how to deal with protocol \"trsa://\" and the rest of the URL</p>",
        "id": 433690134,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338611
    },
    {
        "content": "<p>In case of Datalad, the idea is to store \"git-annex://\" URLs that encode a git-annex remote file reference as a URL.</p>",
        "id": 433690222,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338648
    },
    {
        "content": "<p>Using a handler to access the git-annex URL and download the file would be great</p>",
        "id": 433690265,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713338679
    },
    {
        "content": "<p>Okay, got it. Sounds great! How can I set up my local instance to test it? Can I add any remote store I want? Tried it using the docs, but I have not gotten it to work.</p>",
        "id": 433732855,
        "sender_full_name": "Jan Range",
        "timestamp": 1713353441
    },
    {
        "content": "<p>I've added these JVM args:</p>\n<div class=\"codehilite\"><pre><span></span><code>        -Ddataverse.files.trsa.type=remote\n        -Ddataverse.files.trsa.label=SomeRemoteStorage\n        -Ddataverse.files.trsa.base-url=trsa://\n        -Ddataverse.files.trsa.base-store=trsa\n</code></pre></div>\n<p>The script:</p>\n<div class=\"codehilite\" data-code-language=\"Bash\"><pre><span></span><code><span class=\"nb\">export</span><span class=\"w\"> </span><span class=\"nv\">API_TOKEN</span><span class=\"o\">=</span>7a51588f-8422-4868-bc66-c791016e4a30\n<span class=\"nb\">export</span><span class=\"w\"> </span><span class=\"nv\">SERVER_URL</span><span class=\"o\">=</span>http://localhost:8080\n<span class=\"nb\">export</span><span class=\"w\"> </span><span class=\"nv\">PERSISTENT_ID</span><span class=\"o\">=</span>doi:10.5072/FK2/ZTXNOV\n<span class=\"nb\">export</span><span class=\"w\"> </span><span class=\"nv\">JSON_DATA</span><span class=\"o\">=</span><span class=\"k\">$(</span>&lt;body.json<span class=\"k\">)</span>\n\ncurl<span class=\"w\"> </span>-H<span class=\"w\"> </span><span class=\"s2\">\"X-Dataverse-key: </span><span class=\"nv\">$API_TOKEN</span><span class=\"s2\">\"</span><span class=\"w\"> </span>-X<span class=\"w\"> </span>POST<span class=\"w\"> </span><span class=\"s2\">\"</span><span class=\"nv\">$SERVER_URL</span><span class=\"s2\">/api/datasets/:persistentId/add?persistentId=</span><span class=\"nv\">$PERSISTENT_ID</span><span class=\"s2\">\"</span><span class=\"w\"> </span>-F<span class=\"w\"> </span><span class=\"s2\">\"jsonData=</span><span class=\"nv\">$JSON_DATA</span><span class=\"s2\">\"</span>\n</code></pre></div>\n<p>The request body:</p>\n<div class=\"codehilite\" data-code-language=\"JSON\"><pre><span></span><code><span class=\"p\">{</span>\n<span class=\"w\">  </span><span class=\"nt\">\"description\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"A remote image.\"</span><span class=\"p\">,</span>\n<span class=\"w\">  </span><span class=\"nt\">\"storageIdentifier\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"trsa://hello/testlogo.png\"</span><span class=\"p\">,</span>\n<span class=\"w\">  </span><span class=\"nt\">\"checksumType\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"MD5\"</span><span class=\"p\">,</span>\n<span class=\"w\">  </span><span class=\"nt\">\"md5Hash\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"509ef88afa907eaf2c17c1c8d8fde77e\"</span><span class=\"p\">,</span>\n<span class=\"w\">  </span><span class=\"nt\">\"label\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"testlogo.png\"</span><span class=\"p\">,</span>\n<span class=\"w\">  </span><span class=\"nt\">\"fileName\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"testlogo.png\"</span><span class=\"p\">,</span>\n<span class=\"w\">  </span><span class=\"nt\">\"mimeType\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"image/png\"</span>\n<span class=\"p\">}</span>\n</code></pre></div>",
        "id": 433737932,
        "sender_full_name": "Jan Range",
        "timestamp": 1713355124
    },
    {
        "content": "<p>Pretty sure I am doing sth wrong <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 433737964,
        "sender_full_name": "Jan Range",
        "timestamp": 1713355134
    },
    {
        "content": "<p>I receive the following message every time I try to add a remote file:</p>\n<p><code>{\"status\":\"ERROR\",\"message\":\"Dataset store configuration does not allow provided storageIdentifier.\"}</code></p>\n<p>The storage identifier follows the base URL scheme but does not match.</p>",
        "id": 433749793,
        "sender_full_name": "Jan Range",
        "timestamp": 1713358630
    },
    {
        "content": "<p>Tried setting the collection storage to the remote store, but without an effect</p>",
        "id": 433750018,
        "sender_full_name": "Jan Range",
        "timestamp": 1713358692
    },
    {
        "content": "<p>I'm not sure if the helps but we have a test on the Java side (that isn't exercised regularly): <a href=\"https://github.com/IQSS/dataverse/blob/v6.2/src/test/java/edu/harvard/iq/dataverse/api/RemoteStoreIT.java\">https://github.com/IQSS/dataverse/blob/v6.2/src/test/java/edu/harvard/iq/dataverse/api/RemoteStoreIT.java</a></p>",
        "id": 433753582,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1713359673
    },
    {
        "content": "<p>Awesome! Thanks for the hint. Could it be that I am missing this line?</p>\n<p><code>-Ddataverse.files.trsa.base-store=file</code></p>\n<p>I thought it had a default, but I will give it a try!</p>",
        "id": 433753920,
        "sender_full_name": "Jan Range",
        "timestamp": 1713359768
    },
    {
        "content": "<p>Could be. I'm pretty sure you need a base store for thumbnails, etc.</p>",
        "id": 433755006,
        "sender_full_name": "Philip Durbin ðŸš€",
        "timestamp": 1713360022
    },
    {
        "content": "<p>Stupid idea, but how would it be if we define this filesystem instance-wide? Instead of connecting to a single dataset, you could access all the datasets. I would think of something like this:</p>\n<div class=\"codehilite\" data-code-language=\"Python\"><pre><span></span><code><span class=\"kn\">from</span> <span class=\"nn\">dataversefs</span> <span class=\"kn\">import</span> <span class=\"n\">DataverseFS</span>\n\n\n<span class=\"n\">fs</span> <span class=\"o\">=</span> <span class=\"n\">DataverseFS</span><span class=\"p\">(</span><span class=\"n\">base_url</span><span class=\"o\">=</span><span class=\"s2\">\"https://demo.dataverse.org\"</span><span class=\"p\">)</span>\n<span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">listdir</span><span class=\"p\">(</span><span class=\"s2\">\"doi:10.70122/FK2/TDI8JO://some/dir\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">file</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s2\">\"doi:10.70122/FK2/TDI8JO://some/dir/myfile.txt\"</span><span class=\"p\">,</span> <span class=\"s2\">\"r\"</span><span class=\"p\">)</span>\n</code></pre></div>",
        "id": 434036705,
        "sender_full_name": "Jan Range",
        "timestamp": 1713443867
    },
    {
        "content": "<p>You don't even need the ://</p>",
        "id": 434036936,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713443936
    },
    {
        "content": "<p>It's not a resolvable DOI UIR but who cares</p>",
        "id": 434036989,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713443952
    },
    {
        "content": "<p>Maybe there is a better way, but I think it would be cool to grab from any dataset you want.</p>",
        "id": 434037087,
        "sender_full_name": "Jan Range",
        "timestamp": 1713443991
    },
    {
        "content": "<p>Maybe for the sake of validity go for <code>doi:10.70122/FK2/TDI8JO?file=/path/to/file</code></p>",
        "id": 434037172,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444006
    },
    {
        "content": "<p>Thats nice!</p>",
        "id": 434037195,
        "sender_full_name": "Jan Range",
        "timestamp": 1713444017
    },
    {
        "content": "<p>It becomes a valid URI this way but is simple to parse because of the \"separator string\"</p>",
        "id": 434037278,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444042
    },
    {
        "content": "<p>If you don't want a parameter, you could use anchors</p>",
        "id": 434037380,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444080
    },
    {
        "content": "<p>True that, havent thought about this. The idea just popped in my head <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 434037409,
        "sender_full_name": "Jan Range",
        "timestamp": 1713444087
    },
    {
        "content": "<p><code>doi:10.70122/FK2/TDI8JO#...</code></p>",
        "id": 434037427,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444093
    },
    {
        "content": "<p>Absolutely! Makes a lot of sense.</p>",
        "id": 434037469,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444106
    },
    {
        "content": "<p>I am a fan of the hash - Looks smooth</p>",
        "id": 434037575,
        "sender_full_name": "Jan Range",
        "timestamp": 1713444128
    },
    {
        "content": "<p>Maybe support both. The names are much shorter when not always needing the full qualified one</p>",
        "id": 434037581,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444129
    },
    {
        "content": "<p>There might be character limitations for anchors!</p>",
        "id": 434037635,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444144
    },
    {
        "content": "<p>I will hack sth. New material for the weekend <span aria-label=\"grinning face with smiling eyes\" class=\"emoji emoji-1f601\" role=\"img\" title=\"grinning face with smiling eyes\">:grinning_face_with_smiling_eyes:</span></p>",
        "id": 434037749,
        "sender_full_name": "Jan Range",
        "timestamp": 1713444181
    },
    {
        "content": "<p>Sorry the correct term is \"fragment\"</p>",
        "id": 434037758,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444185
    },
    {
        "content": "<p>Which even makes more sense here - you want a fragment of a dataset</p>",
        "id": 434037803,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444200
    },
    {
        "content": "<p>Dataset Fragments sounds nice <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 434037920,
        "sender_full_name": "Jan Range",
        "timestamp": 1713444233
    },
    {
        "content": "<blockquote>\n<p>The characters slash (\"/\") and question mark (\"?\") are allowed to    represent data within the fragment identifier.  Beware that some    older, erroneous implementations may not handle this data correctly    when it is used as the base URI for relative references (<a href=\"https://www.rfc-editor.org/rfc/rfc3986#section-5.1\">Section</a>    <a href=\"https://www.rfc-editor.org/rfc/rfc3986#section-5.1\">5.1</a>).</p>\n</blockquote>\n<p><a href=\"https://www.rfc-editor.org/rfc/rfc3986#page-24\">https://www.rfc-editor.org/rfc/rfc3986#page-24</a></p>",
        "id": 434038186,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444309
    },
    {
        "content": "<p>You could even support having a query part</p>",
        "id": 434038738,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444494
    },
    {
        "content": "<p><code>doi:10.70122/FK2/TDI8JO?direct-download=false#path/to/file.ext</code></p>",
        "id": 434038850,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444534
    },
    {
        "content": "<p>Wouldn't it be nice if we had a Dataverse API endpoint like this?</p>",
        "id": 434039528,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1713444752
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"599841\">@Jan Range</span> have you ever tried benchmarking the pyfilesystem? Wondering what kind of performance one could get using the underlying S3 and potentially caching the files locally to make sure multiple usage of a file doesn't reload over and over.</p>",
        "id": 519407738,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1747753025
    },
    {
        "content": "<p>Had a discussion with a few RSEs today that do Electron Microscopy. Their sensors stream a solid 2GiB/s and I was wondering if once they put that kind of data into S3 (maybe Dataverse in the mix) what kind of speed they could achieve reading the data back again.</p>",
        "id": 519408167,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1747753130
    },
    {
        "content": "<p>Currently they heavily rely on filesystems and direct IO to avoid page table madness...</p>",
        "id": 519408283,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1747753161
    },
    {
        "content": "<p>But they also want to expose data to analysis stations using SMB/NFS, so going through a network stack. Wondering if the S3 direct download stuff with PyFilesystem2 would be able to compete.</p>",
        "id": 519408578,
        "sender_full_name": "Oliver Bertuch",
        "timestamp": 1747753223
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"598183\">@Oliver Bertuch</span> I have not benchmarked it yet, but I can test it in the upcoming weeks. </p>\n<p>Iâ€™ve checked the source code, and the <code>fs-s3fs</code> package that provides S3 support in <code>pyFileSystem</code> uses <code>boto3</code>, the official AWS SDK. According to the implementation, it automatically utilizes the Range header and parallel downloads, which should make it noticeably faster than a standard sequential download.</p>\n<p>However, when I tried using both <code>boto3</code> and <code>pyFileSystem</code>â€™s S3 backend, I ran into an issue: these libraries require AWS credentials, even for publicly accessible files. I attempted to extract credentials or any required information from the S3 redirect URL, but that wasnâ€™t sufficient to get these libraries working. Do you have any ideas on how we could make this work using only the pre-signed URL?</p>\n<p>That said, I believe we could still achieve better download speeds by leveraging Range headers and parallelizing the download process ourselves. For reference, I ran a quick benchmark comparing the current, non-parallelized PyDataverse download of a 1.5 GB file to a Rust implementation that uses Range requests for parallel downloading.</p>\n<table>\n<thead>\n<tr>\n<th>Library</th>\n<th>Size</th>\n<th>Time Taken</th>\n<th>Gb/s</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>PyDataverse</td>\n<td>1.5gb</td>\n<td>~90s</td>\n<td>~0.01</td>\n</tr>\n<tr>\n<td>DVCLI (Rust)</td>\n<td>1.5gb</td>\n<td>~30s</td>\n<td>~0.05</td>\n</tr>\n</tbody>\n</table>\n<p>The Rust implementation follows the S3 redirect and uses the Range header to enable partial downloads. It splits the file into 5â€¯MB chunks and distributes the workload across 64 workers, which turned out to be the optimal configuration in my tests. To ensure realistic results, I used a file from production as the test case.</p>\n<p><a href=\"https://darus.uni-stuttgart.de/file.xhtml?persistentId=doi:10.18419/DARUS-444/1&amp;version=1.0\">https://darus.uni-stuttgart.de/file.xhtml?persistentId=doi:10.18419/DARUS-444/1&amp;version=1.0</a></p>\n<p>I am not sure if we can get any faster, since the AWS libraries practically do the same thing. Do you have any ideas how we could match the insane 2gb/s <span aria-label=\"smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 519592552,
        "sender_full_name": "Jan Range",
        "timestamp": 1747828488
    },
    {
        "content": "<p>It could be that my WiFi is not the best to benchmark. I could imagine having a direct cable-based connection would perform even better.</p>",
        "id": 519592945,
        "sender_full_name": "Jan Range",
        "timestamp": 1747828603
    }
]