[
    {
        "content": "<p>Hey Folks,<br>\nWe are running a data packaging task group in GREI and have some questions for the community - kind of urgent on the replies:)</p>\n<p><strong>Which packaging approaches do you consider ‚Äúup-and-coming‚Äù or emerging in your domain (e.g., biomedical, environmental, social sciences)?</strong> </p>\n<p>Thanks so much<br>\nSonia and DV IQSS Team -</p>",
        "id": 553408582,
        "sender_full_name": "Sonia Barbosa",
        "timestamp": 1762183305
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"770128\">@Amber Leahey</span></p>",
        "id": 553408796,
        "sender_full_name": "Sonia Barbosa",
        "timestamp": 1762183357
    },
    {
        "content": "<p>Hmm, my first thought is RO-Crate, which <span class=\"user-mention\" data-user-id=\"602497\">@Bal√°zs Pataki</span> <span class=\"user-mention\" data-user-id=\"614964\">@Eryk Kulikowski</span> <span class=\"user-mention\" data-user-id=\"655610\">@Ozgur Karadeniz</span> and <span class=\"user-mention\" data-user-id=\"660583\">@Dieuwertje Bloemen</span> have all worked on. Bal√°zs recently pointed me to a great writeup of Dataverse support for RO-Crate (all implemented by the folks mentioned above!) over at <a href=\"https://www.researchobject.org/ro-crate/dataverse\">https://www.researchobject.org/ro-crate/dataverse</a> . I opened this issue to remind to to add it to the guides:</p>\n<p>Explain RO-Crate support better in the guides¬†<a href=\"https://github.com/IQSS/dataverse/issues/11934\">#11934</a></p>\n<p>See also <a class=\"stream-topic\" data-stream-id=\"379673\" href=\"/#narrow/channel/379673-dev/topic/RO-Crate/with/547290241\">#dev &gt; RO-Crate</a>! <span aria-label=\"smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 553419580,
        "sender_full_name": "Philip Durbin üöÄ",
        "timestamp": 1762185629
    },
    {
        "content": "<p>Yes, I agree with Phil, definitely RO-Crate!</p>",
        "id": 553419989,
        "sender_full_name": "Bal√°zs Pataki",
        "timestamp": 1762185718
    },
    {
        "content": "<p>Another important packaging standard that Dataverse already supports is BagIt. See <a href=\"https://guides.dataverse.org/en/6.8/installation/config.html#bagit-export\">https://guides.dataverse.org/en/6.8/installation/config.html#bagit-export</a></p>",
        "id": 553622520,
        "sender_full_name": "Philip Durbin üöÄ",
        "timestamp": 1762265180
    },
    {
        "content": "<p>Correct. What standards  do we not support, that we should consider supporting<br>\nThanks</p>",
        "id": 553704473,
        "sender_full_name": "Sonia Barbosa",
        "timestamp": 1762287205
    },
    {
        "content": "<p>Well, right now BagIt is very much a backend thing. Users can't download a BagIt by clicking a button. That might be a nice thing to add, if there's demand for it.</p>",
        "id": 553704676,
        "sender_full_name": "Philip Durbin üöÄ",
        "timestamp": 1762287293
    },
    {
        "content": "<p>agree, i think about system generated DDI Codebooks and READMEs and ask why there isn't a button to add these as items into the deposits? Because downloads detach these data packages from the DV metadata a bit, why not support deposit packages with READMEs and Codebooks by reusing metadata in the Dataverse system?  (which btw some in our community are now supporting see example from UofT (<a href=\"https://dv-readme-gen-dev.deno.dev/\">https://dv-readme-gen-dev.deno.dev/</a>) and UBC (<a href=\"https://github.com/ubc-library-rc/dataverse_utils\">https://github.com/ubc-library-rc/dataverse_utils</a>) and McMaster (<a href=\"https://rdm.mcmaster.ca/readme\">https://rdm.mcmaster.ca/readme</a>) and we are forming a little README integration tool WG- stay tuned)</p>",
        "id": 553724470,
        "sender_full_name": "Amber Leahey",
        "timestamp": 1762293653
    },
    {
        "content": "<p>For Codebooks &gt; this largely exists within DV and with Data Explorer &gt; <br>\n<a href=\"/user_uploads/53090/QWpywxV4iZqBVZ38PJnI6sJm/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/53090/QWpywxV4iZqBVZ38PJnI6sJm/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1833x1018\" src=\"/user_uploads/thumbnail/53090/QWpywxV4iZqBVZ38PJnI6sJm/image.png/840x560.webp\"></a></div>",
        "id": 553724609,
        "sender_full_name": "Amber Leahey",
        "timestamp": 1762293715
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"598112\">Philip Durbin üöÄ</span> <a href=\"#narrow/channel/375707-community/topic/Data.20packaging.20and.20Dataverse/near/553704676\">said</a>:</p>\n<blockquote>\n<p>Well, right now BagIt is very much a backend thing. Users can't download a BagIt by clicking a button. That might be a nice thing to add, if there's demand for it.</p>\n</blockquote>\n<p>agree, and if we can add to the Bagit spec for including DDI XML that would be great. And make this more easily part of Admin workflows, right now we provide exports in Bagit as an alternative to Dataverse - Archivematica integration users. I can see how a stored Bagit copy in addition to the DV storage replication we have will be important in the future.</p>",
        "id": 553724923,
        "sender_full_name": "Amber Leahey",
        "timestamp": 1762293844
    },
    {
        "content": "<p>For biomedical and sensitive data, we are seeing a lot of research data management software, REDCAP, Physio net etc. these systems can export metadata and data for packaging for users to upload to a Dataverse repo, but reviewing these kinds of data deposit workflows to support more standardized approaches would be great.</p>",
        "id": 553725301,
        "sender_full_name": "Amber Leahey",
        "timestamp": 1762294005
    },
    {
        "content": "<p>Geospatial - we need more support for ISO 19115 for specialized geospatial metadata support in DV (which we are working on now...), I think improved identification for .LAZ lidar data and geodatabase continues to be needed.</p>",
        "id": 553725484,
        "sender_full_name": "Amber Leahey",
        "timestamp": 1762294067
    }
]